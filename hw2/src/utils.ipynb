{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_CUDA = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_token = 0\n",
    "SOS_token = 1\n",
    "EOS_token = 2\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name='caption'):\n",
    "        self.name = name\n",
    "        self.trimmed = False\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"PAD\", 1: \"SOS\", 2: \"EOS\"}\n",
    "        self.n_words = 3 # Count default tokens\n",
    "\n",
    "    def index_words(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.index_word(word)\n",
    "\n",
    "    def index_word(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "\n",
    "    # Remove words below a certain count threshold\n",
    "    def trim(self, min_count):\n",
    "        if self.trimmed: return\n",
    "        self.trimmed = True\n",
    "        \n",
    "        keep_words = []\n",
    "        \n",
    "        for k, v in self.word2count.items():\n",
    "            if v >= min_count:\n",
    "                keep_words.append(k)\n",
    "\n",
    "        print('keep_words %s / %s = %.4f' % (\n",
    "            len(keep_words), len(self.word2index), len(keep_words) / len(self.word2index)\n",
    "        ))\n",
    "\n",
    "        # Reinitialize dictionaries\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"PAD\", 1: \"SOS\", 2: \"EOS\"}\n",
    "        self.n_words = 3 # Count default tokens\n",
    "\n",
    "        for word in keep_words:\n",
    "            self.index_word(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lowercase, trim, and remove non-letter characters\n",
    "def normalize(s):\n",
    "    s = s.lower().strip()\n",
    "    s = re.sub(r\"([,.!?])\", r\" \\1 \", s)\n",
    "    s = re.sub(r\"[^a-zA-Z,.!?]+\", r\" \", s)\n",
    "    s = re.sub(r\"\\s+\", r\" \", s).strip()\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# Return a list of indexes, one for each word in the sentence\n",
    "def indexes_from_sentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "def variable_from_sentence(lang, sentence):\n",
    "    indexes = indexes_from_sentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    var = Variable(torch.LongTensor(indexes).view(-1, 1))\n",
    "#     print('var =', var)\n",
    "    if USE_CUDA: var = var.cuda()\n",
    "    return var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '../MLDS_hw2_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames_train = os.listdir(DATA_DIR + 'training_data/feat/')\n",
    "num_videos = len(filenames_train)\n",
    "filepath = os.path.join(DATA_DIR + 'training_data/feat/', filenames_train[0])\n",
    "X_0 = np.load(filepath)\n",
    "if __name__ == '__main__':\n",
    "    print(X_0)\n",
    "num_frames, num_features = X_0.shape\n",
    "if __name__ == '__main__':\n",
    "    print(num_videos, num_frames, num_features)\n",
    "\n",
    "X_train = np.zeros([num_videos, num_frames, num_features])\n",
    "for i, filename in enumerate(filenames_train):\n",
    "    filepath = os.path.join(DATA_DIR + 'training_data/feat/', filename)\n",
    "    X_i = np.load(filepath)\n",
    "    X_train[i, :, :] = X_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames_test = os.listdir(DATA_DIR + 'testing_data/feat/')\n",
    "num_videos_test = len(filenames_test)\n",
    "filepath = os.path.join(DATA_DIR + 'testing_data/feat/', filenames_test[0])\n",
    "X_0 = np.load(filepath)\n",
    "if __name__ == '__main__':\n",
    "    print(X_0)\n",
    "num_frames, num_features = X_0.shape\n",
    "if __name__ == '__main__':\n",
    "    print(num_videos_test, num_frames, num_features)\n",
    "\n",
    "X_test = np.zeros([num_videos_test, num_frames, num_features])\n",
    "for i, filename in enumerate(filenames_test):\n",
    "    filepath = os.path.join(DATA_DIR + 'testing_data/feat/', filename)\n",
    "    X_i = np.load(filepath)\n",
    "    X_test[i, :, :] = X_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DATA_DIR + 'training_label.json') as label_file:\n",
    "    list_of_id_captions_dicts = json.load(label_file)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print(list_of_id_captions_dicts[0])\n",
    "\n",
    "captions_train = [None] * num_videos\n",
    "for id_captions_dict in list_of_id_captions_dicts:\n",
    "    id_ = id_captions_dict['id']\n",
    "    captions = id_captions_dict['caption']\n",
    "    \n",
    "    index = filenames_train.index(id_ + '.npy')\n",
    "    captions_train[index] = captions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
