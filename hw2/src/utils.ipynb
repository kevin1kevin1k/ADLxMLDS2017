{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "from models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_token = 0\n",
    "SOS_token = 1\n",
    "EOS_token = 2\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name='caption'):\n",
    "        self.name = name\n",
    "        self.trimmed = False\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"PAD\", 1: \"SOS\", 2: \"EOS\"}\n",
    "        self.n_words = 3 # Count default tokens\n",
    "\n",
    "    def index_words(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.index_word(word)\n",
    "\n",
    "    def index_word(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "\n",
    "    # Remove words below a certain count threshold\n",
    "    def trim(self, min_count):\n",
    "        if self.trimmed: return\n",
    "        self.trimmed = True\n",
    "        \n",
    "        keep_words = []\n",
    "        \n",
    "        for i in range(self.n_words):\n",
    "            w = self.index2word[i]\n",
    "            if w in ['PAD', 'SOS', 'EOS']:\n",
    "                continue\n",
    "            if self.word2count[w] >= min_count:\n",
    "                keep_words.append(w)\n",
    "            \n",
    "        print('keep_words %s / %s = %.4f' % (\n",
    "            len(keep_words), len(self.word2index), len(keep_words) / len(self.word2index)\n",
    "        ))\n",
    "\n",
    "        # Reinitialize dictionaries\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"PAD\", 1: \"SOS\", 2: \"EOS\"}\n",
    "        self.n_words = 3 # Count default tokens\n",
    "\n",
    "        for word in keep_words:\n",
    "            self.index_word(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lowercase, trim, and remove non-letter characters\n",
    "def normalize(s):\n",
    "    s = s.lower().strip()\n",
    "    s = re.sub(r\"([,.!?])\", r\" \\1 \", s)\n",
    "    s = re.sub(r\"[^a-zA-Z,.!?]+\", r\" \", s)\n",
    "    s = re.sub(r\"\\s+\", r\" \", s).strip()\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return a list of indexes, one for each word in the sentence\n",
    "def indexes_from_sentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "def variable_from_sentence(lang, sentence):\n",
    "    indexes = indexes_from_sentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    var = Variable(torch.LongTensor(indexes).view(-1, 1))\n",
    "    if USE_CUDA: var = var.cuda()\n",
    "    return var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '../MLDS_hw2_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames_train = os.listdir(DATA_DIR + 'training_data/feat/')\n",
    "num_videos = len(filenames_train)\n",
    "filepath = os.path.join(DATA_DIR + 'training_data/feat/', filenames_train[0])\n",
    "X_0 = np.load(filepath)\n",
    "if __name__ == '__main__':\n",
    "    print(X_0)\n",
    "num_frames, num_features = X_0.shape\n",
    "if __name__ == '__main__':\n",
    "    print(num_videos, num_frames, num_features)\n",
    "\n",
    "X_train = np.zeros([num_videos, num_frames, num_features])\n",
    "for i, filename in enumerate(filenames_train):\n",
    "    filepath = os.path.join(DATA_DIR + 'training_data/feat/', filename)\n",
    "    X_i = np.load(filepath)\n",
    "    X_train[i, :, :] = X_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames_test = os.listdir(DATA_DIR + 'testing_data/feat/')\n",
    "num_videos_test = len(filenames_test)\n",
    "filepath = os.path.join(DATA_DIR + 'testing_data/feat/', filenames_test[0])\n",
    "X_0 = np.load(filepath)\n",
    "if __name__ == '__main__':\n",
    "    print(X_0)\n",
    "num_frames, num_features = X_0.shape\n",
    "if __name__ == '__main__':\n",
    "    print(num_videos_test, num_frames, num_features)\n",
    "\n",
    "X_test = np.zeros([num_videos_test, num_frames, num_features])\n",
    "for i, filename in enumerate(filenames_test):\n",
    "    filepath = os.path.join(DATA_DIR + 'testing_data/feat/', filename)\n",
    "    X_i = np.load(filepath)\n",
    "    X_test[i, :, :] = X_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DATA_DIR + 'training_label.json') as label_file:\n",
    "    list_of_id_captions_dicts = json.load(label_file)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print(list_of_id_captions_dicts[0])\n",
    "\n",
    "captions_train = [None] * num_videos\n",
    "for id_captions_dict in list_of_id_captions_dicts:\n",
    "    id_ = id_captions_dict['id']\n",
    "    captions = id_captions_dict['caption']\n",
    "    \n",
    "    index = filenames_train.index(id_ + '.npy')\n",
    "    captions_train[index] = captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "captions_train_normalized = [[normalize(caption) for caption in captions] for captions in captions_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_captions(captions_list):\n",
    "    filtered_captions_list = []\n",
    "    for captions in captions_list:\n",
    "        filtered_captions = []\n",
    "        for caption in captions:\n",
    "            L = len(caption.split(' '))\n",
    "            if MIN_LENGTH <= L <= MAX_LENGTH:\n",
    "                filtered_captions.append(caption)\n",
    "        filtered_captions_list.append(filtered_captions)\n",
    "    return filtered_captions_list\n",
    "\n",
    "captions_train_filtered = filter_captions(captions_train_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_lang = Lang()\n",
    "\n",
    "print(\"Indexing words...\")\n",
    "for captions in captions_train_filtered:\n",
    "    for caption in captions:\n",
    "        output_lang.index_words(caption)\n",
    "\n",
    "print('Indexed {} words in output'.format(output_lang.n_words))\n",
    "\n",
    "output_lang.trim(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_length_count(captions_list):\n",
    "    length_count = list()\n",
    "    for captions in captions_list:\n",
    "        if len(captions) == 0:\n",
    "            print('NO CAPTION!!')\n",
    "        for caption in captions:\n",
    "            L = len(caption.split(' '))\n",
    "            length_count.append(L)\n",
    "\n",
    "    print(min(length_count), max(length_count), len(length_count))\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    %matplotlib inline\n",
    "\n",
    "    plt.hist(length_count, max(length_count) - min(length_count) + 1)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
